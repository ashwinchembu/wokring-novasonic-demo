<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Nova Sonic Voice Test</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }
        
        .container {
            background: white;
            border-radius: 20px;
            padding: 40px;
            max-width: 800px;
            width: 100%;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
        }
        
        h1 {
            text-align: center;
            color: #333;
            margin-bottom: 10px;
            font-size: 2.5em;
        }
        
        .subtitle {
            text-align: center;
            color: #666;
            margin-bottom: 30px;
            font-size: 1.1em;
        }
        
        .status {
            text-align: center;
            padding: 15px;
            border-radius: 10px;
            margin-bottom: 20px;
            font-weight: 500;
        }
        
        .status.connected {
            background: #d4edda;
            color: #155724;
        }
        
        .status.disconnected {
            background: #f8d7da;
            color: #721c24;
        }
        
        .status.talking {
            background: #d1ecf1;
            color: #0c5460;
        }
        
        .controls {
            display: flex;
            gap: 15px;
            justify-content: center;
            margin-bottom: 30px;
        }
        
        button {
            padding: 15px 30px;
            font-size: 16px;
            border: none;
            border-radius: 10px;
            cursor: pointer;
            font-weight: 600;
            transition: all 0.3s;
            min-width: 150px;
        }
        
        button:hover {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(0,0,0,0.2);
        }
        
        button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }
        
        #startBtn {
            background: #28a745;
            color: white;
        }
        
        #stopBtn {
            background: #dc3545;
            color: white;
        }
        
        .transcript-container {
            background: #f8f9fa;
            border-radius: 10px;
            padding: 20px;
            max-height: 400px;
            overflow-y: auto;
            margin-bottom: 20px;
        }
        
        .transcript-entry {
            margin-bottom: 15px;
            padding: 10px;
            border-radius: 8px;
        }
        
        .transcript-entry.user {
            background: #e3f2fd;
            margin-left: 40px;
        }
        
        .transcript-entry.assistant {
            background: #f3e5f5;
            margin-right: 40px;
        }
        
        .speaker {
            font-weight: bold;
            margin-bottom: 5px;
            text-transform: uppercase;
            font-size: 0.85em;
        }
        
        .user .speaker {
            color: #1976d2;
        }
        
        .assistant .speaker {
            color: #7b1fa2;
        }
        
        .visualizer {
            width: 100%;
            height: 100px;
            background: #000;
            border-radius: 10px;
            margin-bottom: 20px;
        }
        
        .info {
            background: #fff3cd;
            border: 1px solid #ffc107;
            border-radius: 8px;
            padding: 15px;
            margin-bottom: 20px;
        }
        
        .info strong {
            color: #856404;
        }
        
        .pulse {
            animation: pulse 1.5s infinite;
        }
        
        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.5; }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ðŸŽ¤ Nova Sonic Voice Test</h1>
        <p class="subtitle">Real-time voice conversation with Amazon Bedrock</p>
        
        <div id="status" class="status disconnected">
            Not Connected
        </div>
        
        <div class="info">
            <strong>Instructions:</strong><br>
            1. Click "Start Conversation"<br>
            2. Allow microphone access when prompted<br>
            3. Start speaking - Nova Sonic will respond!<br>
            4. Click "Stop" when done
        </div>
        
        <div class="controls">
            <button id="startBtn" onclick="startConversation()">Start Conversation</button>
            <button id="stopBtn" onclick="stopConversation()" disabled>Stop</button>
        </div>
        
        <canvas id="visualizer" class="visualizer"></canvas>
        
        <div class="transcript-container" id="transcript">
            <div style="text-align: center; color: #999;">
                Transcripts will appear here...
            </div>
        </div>
    </div>

    <script>
        let sessionId = null;
        let audioContext = null;
        let mediaStream = null;
        let processor = null;
        let eventSource = null;
        let isRecording = false;
        let audioQueue = [];
        let isPlaying = false;
        
        const API_URL = 'http://localhost:8000';
        const statusDiv = document.getElementById('status');
        const transcriptDiv = document.getElementById('transcript');
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const canvas = document.getElementById('visualizer');
        const canvasCtx = canvas.getContext('2d');
        
        // Audio visualization
        function drawVisualizer(dataArray) {
            const WIDTH = canvas.width;
            const HEIGHT = canvas.height;
            
            canvasCtx.fillStyle = '#000';
            canvasCtx.fillRect(0, 0, WIDTH, HEIGHT);
            
            const barWidth = (WIDTH / dataArray.length) * 2.5;
            let x = 0;
            
            for (let i = 0; i < dataArray.length; i++) {
                const barHeight = (dataArray[i] / 255) * HEIGHT;
                
                const r = barHeight + 25;
                const g = 50;
                const b = 250;
                
                canvasCtx.fillStyle = `rgb(${r}, ${g}, ${b})`;
                canvasCtx.fillRect(x, HEIGHT - barHeight, barWidth, barHeight);
                
                x += barWidth + 1;
            }
        }
        
        function updateStatus(message, type) {
            statusDiv.textContent = message;
            statusDiv.className = `status ${type}`;
        }
        
        function addTranscript(speaker, text) {
            if (transcriptDiv.children.length === 1 && 
                transcriptDiv.children[0].textContent.includes('Transcripts will appear')) {
                transcriptDiv.innerHTML = '';
            }
            
            const entry = document.createElement('div');
            entry.className = `transcript-entry ${speaker}`;
            entry.innerHTML = `
                <div class="speaker">${speaker}</div>
                <div>${text}</div>
            `;
            transcriptDiv.appendChild(entry);
            transcriptDiv.scrollTop = transcriptDiv.scrollHeight;
        }
        
        async function startConversation() {
            try {
                updateStatus('Creating session...', 'connected');
                
                // Create session
                const response = await fetch(`${API_URL}/session/start`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        system_prompt: 'You are a friendly AI assistant. Keep your responses concise, around 2-3 sentences.'
                    })
                });
                
                const data = await response.json();
                sessionId = data.session_id;
                
                console.log('Session created:', sessionId);
                
                // Initialize audio
                audioContext = new (window.AudioContext || window.webkitAudioContext)({
                    sampleRate: 24000  // Output sample rate
                });
                
                // Get microphone access
                mediaStream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        sampleRate: 16000,
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: true
                    }
                });
                
                // Setup audio processing
                const source = audioContext.createMediaStreamSource(mediaStream);
                processor = audioContext.createScriptProcessor(4096, 1, 1);
                
                let analyser = audioContext.createAnalyser();
                analyser.fftSize = 256;
                source.connect(analyser);
                source.connect(processor);
                processor.connect(audioContext.destination);
                
                const dataArray = new Uint8Array(analyser.frequencyBinCount);
                
                function visualize() {
                    if (!isRecording) return;
                    requestAnimationFrame(visualize);
                    analyser.getByteFrequencyData(dataArray);
                    drawVisualizer(dataArray);
                }
                
                processor.onaudioprocess = async (e) => {
                    if (!isRecording) return;
                    
                    const inputData = e.inputBuffer.getChannelData(0);
                    const pcmData = new Int16Array(inputData.length);
                    
                    for (let i = 0; i < inputData.length; i++) {
                        pcmData[i] = Math.max(-32768, Math.min(32767, inputData[i] * 32768));
                    }
                    
                    // Convert to base64
                    const base64 = btoa(String.fromCharCode(...new Uint8Array(pcmData.buffer)));
                    
                    // Send to server
                    try {
                        await fetch(`${API_URL}/audio/chunk`, {
                            method: 'POST',
                            headers: { 'Content-Type': 'application/json' },
                            body: JSON.stringify({
                                session_id: sessionId,
                                audio_data: base64,
                                format: 'pcm',
                                sample_rate: 16000,
                                channels: 1
                            })
                        });
                    } catch (err) {
                        console.error('Error sending audio:', err);
                    }
                };
                
                // Start event stream
                eventSource = new EventSource(`${API_URL}/events/stream/${sessionId}`);
                
                eventSource.addEventListener('transcript', (e) => {
                    const data = JSON.parse(e.data);
                    addTranscript(data.speaker, data.text);
                });
                
                eventSource.addEventListener('audio', (e) => {
                    const data = JSON.parse(e.data);
                    playAudioResponse(data.audio_data);
                });
                
                eventSource.onerror = (err) => {
                    console.error('EventSource error:', err);
                };
                
                isRecording = true;
                visualize();
                
                updateStatus('ðŸŽ¤ Listening... Speak now!', 'talking pulse');
                startBtn.disabled = true;
                stopBtn.disabled = false;
                
            } catch (error) {
                console.error('Error:', error);
                updateStatus('Error: ' + error.message, 'disconnected');
            }
        }
        
        async function playAudioResponse(base64Audio) {
            try {
                const binaryString = atob(base64Audio);
                const bytes = new Uint8Array(binaryString.length);
                for (let i = 0; i < binaryString.length; i++) {
                    bytes[i] = binaryString.charCodeAt(i);
                }
                
                const pcmData = new Int16Array(bytes.buffer);
                const audioBuffer = audioContext.createBuffer(1, pcmData.length, 24000);
                const channelData = audioBuffer.getChannelData(0);
                
                for (let i = 0; i < pcmData.length; i++) {
                    channelData[i] = pcmData[i] / 32768.0;
                }
                
                const source = audioContext.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(audioContext.destination);
                source.start();
                
                updateStatus('ðŸ”Š AI is speaking...', 'talking');
                
                source.onended = () => {
                    if (isRecording) {
                        updateStatus('ðŸŽ¤ Listening... Speak now!', 'talking pulse');
                    }
                };
                
            } catch (error) {
                console.error('Error playing audio:', error);
            }
        }
        
        async function stopConversation() {
            isRecording = false;
            
            if (processor) {
                processor.disconnect();
            }
            
            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
            }
            
            if (eventSource) {
                eventSource.close();
            }
            
            if (sessionId) {
                try {
                    await fetch(`${API_URL}/audio/end`, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({ session_id: sessionId })
                    });
                    
                    await fetch(`${API_URL}/session/${sessionId}`, {
                        method: 'DELETE'
                    });
                } catch (err) {
                    console.error('Error ending session:', err);
                }
            }
            
            if (audioContext) {
                audioContext.close();
            }
            
            updateStatus('Conversation ended', 'disconnected');
            startBtn.disabled = false;
            stopBtn.disabled = true;
            
            // Clear canvas
            canvasCtx.fillStyle = '#000';
            canvasCtx.fillRect(0, 0, canvas.width, canvas.height);
        }
        
        // Initialize canvas size
        canvas.width = canvas.offsetWidth;
        canvas.height = canvas.offsetHeight;
    </script>
</body>
</html>

